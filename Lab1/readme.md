### Лабораторна робота №1

**Тема:** Паралельне множення матриці на вектор з використанням MPI  
**Дисципліна:** Розподілені обчислення

---

### Мета роботи

Ознайомитися з основами розподілених обчислень за допомогою технології MPI (Message Passing Interface) та дослідити ефективність паралельного алгоритму множення матриці на вектор у порівнянні з послідовною реалізацією.

---

### Завдання

1. Реалізувати послідовний алгоритм множення матриці на вектор (**Exercise 2**, Tasks 1–5).
2. Реалізувати паралельний алгоритм множення матриці на вектор з використанням MPI (**Exercise 4**, Tasks 1–11).
3. Провести експериментальні вимірювання часу виконання послідовної та паралельної програм для різних розмірів матриці та різної кількості процесів.
4. Обчислити прискорення паралельної програми та зробити висновки щодо ефективності (**Exercise 4.12**).

---

### Теоретичні відомості

Розглядається множення квадратної матриці розміру $n \times n$ на вектор розміру $n$:

$$
y = A \cdot x,
$$

де

- $A = (a_{ij})$ — матриця розміру $n \times n$,
- $x = (x_j)$ — вектор-стовпець,
- $y = (y_i)$ — результат множення.

Компоненти вектора $y$ обчислюються за формулою:

$$
y_i = \sum_{j=1}^{n} a_{ij} x_j,\quad i = 1, \dots, n.
$$

У роботі використовується модель **процесів з обміном повідомлень**, реалізована бібліотекою MPI.

---

### Формули для аналізу ефективності

#### Час виконання

Позначення:

- $T_{\text{serial}}$ — час роботи послідовного алгоритму;
- $T_{\text{parallel}}$ — час роботи паралельного алгоритму на $p$ процесах.

#### Прискорення паралельної програми

$$
S_p = \frac{T_{\text{serial}}}{T_{\text{parallel}}}
$$

#### Ефективність паралельної програми

$$
E_p = \frac{S_p}{p} = \frac{T_{\text{serial}}}{p \cdot T_{\text{parallel}}}
$$

---

### Опис реалізації

#### 1. Вихідні дані

В обох реалізаціях (послідовній та паралельній) використовуються однакові вхідні дані:

- Матриця $A$ ініціалізується за правилом:
  $$
  a_{ij} = i + j + 1,
  $$
  де $i, j$ — індекси рядка та стовпця (починаючи з 0).

Такий вибір дозволяє легко перевіряти коректність результату.

---

#### 2. Послідовна реалізація (`serial_mv`)

Послідовна програма (`serial/main.cpp`):

1. Зчитує з клавіатури розмір $n$ (розмір матриці та вектора).
2. Динамічно виділяє пам’ять під матрицю $A$, вектор $x$ та вектор результату $y$ (у коді реалізовано через `std::vector<double>`).
3. Ініціалізує матрицю та вектор за вказаними вище формулами.
4. Вимірює час виконання множення матриці на вектор (за допомогою функції `clock()` з `<ctime>`).
5. Виводить час виконання та, для невеликих розмірів (наприклад, $n \le 10$), елементи вектора результату.

---

#### 3. Паралельна реалізація (`mpi_mv`) з MPI

Паралельна програма (`mpi/main.cpp`) реалізована з використанням MPI:

1. **Ініціалізація MPI**:
    - `MPI_Init`, `MPI_Comm_size`, `MPI_Comm_rank`.
2. **Введення розміру** $n$ на процесі з рангом 0 та розсилка значення всім процесам (`MPI_Bcast`).
3. **Розподіл рядків матриці між процесами**:
    - Обчислення, скільки рядків матриці отримує кожен процес (майже рівномірно: деякі процеси можуть отримати на один рядок більше).
    - Формування масивів `send_counts` та `displs` для виклику `MPI_Scatterv`.
4. **Розсилка вектора** $x$ усім процесам (`MPI_Bcast`).
5. **Розподіл матриці**:
    - Процес 0 зберігає повну матрицю $A$;
    - Кожен процес отримує свої рядки матриці у локальний буфер `localA` за допомогою `MPI_Scatterv`.
6. **Паралельне обчислення**:
    - Кожен процес обчислює свою частину вектора результату `local_y` для закріплених за ним рядків.
    - Перед обчисленням і після нього використовується `MPI_Barrier` та `MPI_Wtime` для вимірювання часу.
7. **Збір результатів**:
    - Всі локальні частини вектора результату збираються на процесі 0 за допомогою `MPI_Gatherv` у вектор `y_{\text{parallel}}`.
8. **Перевірка коректності**:
    - На процесі 0 виконується послідовне множення (функція `multiply_serial`) та порівняння результатів поелементно з допустимою похибкою $TOL = 10^{-6}$.
    - У випадку збігу виводиться повідомлення  
      `=== Parallel result matches serial computation ===`.

---

### Результати вимірювань

Нижче наведений шаблон таблиці для внесення експериментальних даних.  
Програми запускаються для різних розмірів матриці (наприклад, $n = 10, 100, 1000, 2000, 5000, 10000, 20000$) та різної кількості процесів ($p = 2, 4, 8$).

#### Позначення для таблиці

- $T_{\text{serial}}$ — час послідовного алгоритму;
- $T_2$ — час паралельного алгоритму на $p = 2$ процесах;
- $T_4$ — час на $p = 4$;
- $T_8$ — час на $p = 8$.

Прискорення, що порівнюють послідовний та паралельні запуски:

$$
S_{\text{serial vs 2}} = \frac{T_{\text{serial}}}{T_2},\quad
S_{\text{serial vs 4}} = \frac{T_{\text{serial}}}{T_4},\quad
S_{\text{serial vs 8}} = \frac{T_{\text{serial}}}{T_8}.
$$

Відносне прискорення між паралельними конфігураціями:

$$
S_{2 \to 4} = \frac{T_2}{T_4},\quad
S_{2 \to 8} = \frac{T_2}{T_8},\quad
S_{4 \to 8} = \frac{T_4}{T_8}.
$$

> **Приклад заповненої таблиці:**

| n     | T_serial (s) | T₂ (s)   | T₄ (s)   | T₈ (s)   | S(serial vs 2) | S(serial vs 4) | S(serial vs 8) | S(2 vs 4) | S(2 vs 8) | S(4 vs 8) |
| ----- | ------------ | -------- | -------- | -------- | -------------- | -------------- | -------------- | --------- | --------- | --------- |
| 10    | 0.000006     | 0.000006 | 0.000002 | 0.000013 | 1.00           | 3.00           | 0.46           | 3.00      | 0.46      | 0.15      |
| 100   | 0.000089     | 0.000011 | 0.000010 | 0.000019 | 8.09           | 8.90           | 4.68           | 1.10      | 0.58      | 0.53      |
| 1000  | 0.001564     | 0.000894 | 0.000663 | 0.000634 | 1.75           | 2.36           | 2.47           | 1.35      | 1.41      | 1.05      |
| 2000  | 0.006436     | 0.006808 | 0.003367 | 0.002381 | 0.95           | 1.91           | 2.70           | 2.02      | 2.86      | 1.41      |
| 5000  | 0.041226     | 0.021901 | 0.011032 | 0.012416 | 1.88           | 3.74           | 3.32           | 1.99      | 1.76      | 0.89      |
| 10000 | 0.162701     | 0.086725 | 0.046134 | 0.053576 | 1.88           | 3.53           | 3.04           | 1.88      | 1.62      | 0.86      |
| 20000 | 1.236210     | 1.049030 | 0.534615 | 0.660715 | 1.18           | 2.31           | 1.87           | 1.96      | 1.59      | 0.81      |

---

### Висновки

1. Реалізовано послідовний та паралельний варіанти множення матриці на вектор. Для перевірки коректності паралельної реалізації використано порівняння з послідовним результатом, яке показало збіг результатів з точністю до $10^{-6}$.
2. При малих розмірах матриці (наприклад, $n = 10$) накладні витрати на створення процесів та обмін даними по MPI є співрозмірними або навіть більшими за час обчислень, тому прискорення може бути меншим за 1.
3. При збільшенні розміру задачі (зростанні $n$) частка власне обчислень зростає, і паралельна реалізація починає показувати помітне прискорення.
4. Найбільше прискорення спостерігається при використанні більшої кількості процесів (наприклад, 8 процесів) на великих розмірах матриці. При цьому ефективність $E_p$ менша за 1 через накладні витрати синхронізації та комунікації між процесами.
5. Отримані результати підтверджують доцільність застосування розподілених обчислень для задач великої розмірності та демонструють класичну поведінку прискорення й ефективності паралельних алгоритмів.

---

### Команди для компіляції та запуску

```bash
# Компіляція
mpic++ ./mpi/main.cpp -o mpi_mv
g++   ./serial/main.cpp -o serial_mv

# Послідовна версія
./serial_mv

# Паралельна версія (флажок -np number — для вказання кількості процесів)
mpirun -np number ./mpi_mv
